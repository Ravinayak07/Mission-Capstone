Demand for more intelligent and context-aware voice interfaces in recent years has driven research on VAD systems capable of managing not only speaker differentiation, emotional tone, and environment classification but also speech detection. This has spurred research on hybrid architectures combining CNNs with transformer-based components able to vary temporal features depending on their contextual relevance or with attention mechanisms. These models not only find speech more precisely but also provide information on the speaker's intention or the type of the background surroundings. These developments capture the increasing complexity and expectations placed on voice-based systems in contemporary human-computer interaction configurations.
